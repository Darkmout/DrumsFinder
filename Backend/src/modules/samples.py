#Open a midi file and a wav and output labelled window of the wave (need to be maintained with the new python midi
import os
import numpy as np 

import audio
import midiProxy
import tensorFlowUtils



                
'''
write samples from a wave and midi file
'''
def writeSamples(midiPath, audioPath, outputPath):
    midi = midiProxy.loadMidiDrums(midiPath)
    audioLoad = audio.load(audioPath)
    wave = audioLoad[1]
    rate = audioLoad[0]
    

    #check correctness
    #spectrogram, samplingRate = audio.performFFTs(audioLoad)
    #audio.visualizeSpectrogram(wave=None, spectrogram=spectrogram, midi=midi, name=midiPath)

    #lowest frequency = 10Hz = 0.1s per wave
    #time between 16th notes : 200bpm = 300 b/ms = 0.3 b/s = 0.075 16th/s
    step = 0.525 #window of the sound saved in seconds
    samples = int(step * rate) #number of samples to save
    preDelay = 0.05
    for midiEvent in midi:  
        #get the name and the time of the midi event
        eventName = midiEvent['notes'] #midiProxy.getVectorToNote(midiEvent['notes']) #from [0,0,1,0...] to [40, 36]
        time = midiEvent["startTime"]
        
        #if the event is not in the wave
        min = int(rate * (time - preDelay))
        max = int(rate * (time - preDelay)) + samples
        if min < 0 or max > len(wave):
            continue
        
        #create folder for the samples
        directory = outputPath + "/" + str(eventName)
        if not os.path.exists(directory):
            os.makedirs(directory)

        # fadein and fadeout to prevent aliasing in the fft ?
        # fadedWave = np.array([[int(wave[min+i][0] * fadeMask[i]), int(wave[min+i][1] * fadeMask[i])] for i in xrange(samples)], dtype = wave.dtype)
     
        #write the isolated wave from the sample
        audio.write(directory + "/" + audioPath.split("/")[-1] + str(time) + ".wav", rate, wave[min:max])
#         audio.write(directory + "/" + str(time) + "f.wav", rate, fadedWave)
        
        print directory + "/" +  audioPath.split("/")[-1] + str(time) + ".wav"
   
'''
do as writeSamples but with a folder of files containing midi and wave files with the same name
''' 
def writeSamplesFromFolder(outputPath, inputPath):
    for root, dirs, files in os.walk(inputPath):
        for idx, file in enumerate(files):
            if file.endswith(".wav"):
                path = (os.path.join(root, file))
                writeSamples(path[:-3]+"mid", path, outputPath)
                
'''
load a folder of samples generated by "write samples", then do the fft.
call this to create a training set
'''
def loadSamplesFolder(path, fileLimit = 200):
    X = []
    Y = []
    paths = []
    #Load paths
    for root, dirs, files in os.walk(path):
        for idx, file in enumerate(files):
            if file.endswith(".wav"):
                paths.append((root.split("/")[-1], os.path.join(root, file)))
     
    #get some random path
    paths = tensorFlowUtils.limitMultilabelSamples(paths, fileLimit)
    #Load the files and do the fft
    for label, path in paths:
        wave = audio.load(path)
        spectrogram, samplingRate = audio.performFFTs(wave)
        #audio.visualizeSpectrogram(wave=None, spectrogram=spectrogram, midi=None, name=label)
        
        xn = np.fliplr(np.array([fft["frequencies"] for i,fft in enumerate(spectrogram)])).transpose()
        X.append(xn)
        Y.append(eval(label))
    
    return np.array(X), np.array(Y) 


# 
# writeSamplesFromFolder("../../../Data/samples/testAtlantis/test", "../../../Data/handmade/test")
# writeSamplesFromFolder("../../../Data/samples/testAtlantis/train", "../../../Data/handmade/train")
# print "Done !"
